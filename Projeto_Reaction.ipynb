{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração das Imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extação Concluida!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from shutil import copyfile\n",
    "\n",
    "emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "participants = glob.glob(\"base\\\\source_emotion\\\\*\")\n",
    "\n",
    "for x in participants:\n",
    "    part = \"%s\" % x[-4:]\n",
    "    for sessions in glob.glob(\"%s\\\\*\" % x):\n",
    "        for files in glob.glob(\"%s\\\\*\" % sessions):\n",
    "            current_session = files[25:-30]\n",
    "\n",
    "            file = open(files, 'r')\n",
    "\n",
    "            emotion = int(float(file.readline()))\n",
    "\n",
    "            sourcefile_emotion = glob.glob(\"base\\source_images\\\\%s\\\\%s\\\\*\" % (part, current_session))[-1]\n",
    "            sourcefile_neutral = glob.glob(\"base\\source_images\\\\%s\\\\%s\\\\*\" % (part, current_session))[0]\n",
    "\n",
    "            dest_neut = \"base\\sorted_set\\\\neutral\\\\%s\" % sourcefile_neutral[28:]\n",
    "            dest_emot = \"base\\sorted_set\\\\%s\\\\%s\" % (emotions[emotion], sourcefile_emotion[28:])\n",
    "\n",
    "            copyfile(sourcefile_neutral, dest_neut)\n",
    "            copyfile(sourcefile_emotion, dest_emot)\n",
    "            \n",
    "print(\"Extação Concluida!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção das Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emoção neutral concluída!\n",
      "Emoção anger concluída!\n",
      "Emoção contempt concluída!\n",
      "Emoção disgust concluída!\n",
      "Emoção fear concluída!\n",
      "Emoção happy concluída!\n",
      "Emoção sadness concluída!\n",
      "Emoção surprise concluída!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "\n",
    "faceDet = cv2.CascadeClassifier(\"C:\\\\opencv\\\\build\\\\etc\\\\haarcascades\\\\haarcascade_frontalface_default.xml\")\n",
    "faceDet_two = cv2.CascadeClassifier(\"C:\\\\opencv\\\\build\\\\etc\\\\haarcascades\\\\haarcascade_frontalface_alt2.xml\")\n",
    "faceDet_three = cv2.CascadeClassifier(\"C:\\\\opencv\\\\build\\\\etc\\\\haarcascades\\\\haarcascade_frontalface_alt.xml\")\n",
    "faceDet_four = cv2.CascadeClassifier(\"C:\\\\opencv\\\\build\\\\etc\\\\haarcascades\\\\haarcascade_frontalface_alt_tree.xml\")\n",
    "\n",
    "emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "\n",
    "\n",
    "def detect_faces(emotion):\n",
    "    files = glob.glob(\"base\\\\sorted_set\\\\{}\\\\*\".format(emotion))\n",
    "\n",
    "    filenumber = 0\n",
    "    i = 1\n",
    "    for f in files:\n",
    "        frame = cv2.imread(f)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        face = faceDet.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        face_two = faceDet_two.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        face_three = faceDet_three.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        face_four = faceDet_four.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "        if len(face) == 1:\n",
    "            facefeatures = face\n",
    "        elif len(face_two) == 1:\n",
    "            facefeatures = face_two\n",
    "        elif len(face_three) == 1:\n",
    "            facefeatures = face_three\n",
    "        elif len(face_four) == 1:\n",
    "            facefeatures = face_four\n",
    "        else:\n",
    "            facefeatures = \"\"\n",
    "\n",
    "\n",
    "        for (x, y, w, h,) in facefeatures:\n",
    "            # print(\"Face Encontrada no arquivo {}: {}\".format(i, f))\n",
    "\n",
    "            gray = gray[y:y + h, x:x + w]\n",
    "\n",
    "            try:\n",
    "                out = cv2.resize(gray, (350, 350))\n",
    "                cv2.imwrite(\"base\\\\dataset\\\\%s\\\\%s.jpg\" % (emotion, filenumber), out)\n",
    "            except:\n",
    "                pass\n",
    "        i = i + 1\n",
    "        filenumber += 1\n",
    "\n",
    "\n",
    "for emotion in emotions:\n",
    "    detect_faces(emotion)\n",
    "    print(\"Emoção {} concluída!\".format(emotion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 84.85%\n",
      "Margin of Error for More and Less: 5.67%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "emotions = [\"happy\", \"surprise\"]\n",
    "\n",
    "regr = tree.DecisionTreeRegressor(criterion='mae', splitter='best')\n",
    "\n",
    "file = open('base\\\\resultados.txt', 'w')\n",
    "\n",
    "def get_files(emotion):\n",
    "    files = glob.glob(\"base\\dataset\\\\{}\\\\*\".format(emotion))\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files) * 0.7)]\n",
    "    test = files[-int(len(files) * 0.3):]\n",
    "    return training, test\n",
    "\n",
    "\n",
    "def make_sets():\n",
    "    training_X = []\n",
    "    training_y = []\n",
    "    test_X = []\n",
    "    test_y = []\n",
    "\n",
    "    for emotion in emotions:\n",
    "\n",
    "        training, test = get_files(emotion)\n",
    "\n",
    "        for item in training:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            training_X.append(gray)\n",
    "            training_y.append(emotions.index(emotion))\n",
    "\n",
    "        for item in test:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            test_X.append(gray)\n",
    "            test_y.append(emotions.index(emotion))\n",
    "\n",
    "    return training_X, training_y, test_X, test_y\n",
    "\n",
    "def run_recognizer(regr):\n",
    "    training_X, training_y, test_X, test_y = make_sets()\n",
    "\n",
    "    training_X = np.array(training_X)\n",
    "    training_y = np.array(training_y)\n",
    "\n",
    "    test_X = np.array(test_X)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    training_X = training_X.reshape(106, 350*350)\n",
    "    test_X = test_X.reshape(44, 350*350)\n",
    "\n",
    "    regr = regr.fit(training_X, training_y)\n",
    "\n",
    "    predict = regr.predict(test_X)\n",
    "\n",
    "    return accuracy_score(predict, test_y)\n",
    "\n",
    "\n",
    "metascore = []\n",
    "\n",
    "for i in range(0, 3):\n",
    "    correct = run_recognizer(regr)\n",
    "    file.write(\"{} {}\\n\".format(i, correct))\n",
    "    #print(\"{}\".format(i))\n",
    "    metascore.append(correct)\n",
    "\n",
    "metascore = np.array(metascore)\n",
    "\n",
    "print(\"Accuracy: %1.2f%%\" % (metascore.mean()*100))\n",
    "print(\"Margin of Error for More and Less: %1.2f%%\" % (metascore.std()*100))\n",
    "\n",
    "file.write(\"{}\\n\".format(metascore.mean()))\n",
    "file.write(\"{}\\n\".format(metascore.std()))\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# RandomForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.47%\n",
      "Margin of Error for More and Less: 0.73%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "# emotions = [\"happy\", \"surprise\"]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500, max_features=.3)\n",
    "\n",
    "file = open('base\\\\resultados.txt', 'w')\n",
    "\n",
    "def get_files(emotion):\n",
    "    files = glob.glob(\"base\\dataset\\\\{}\\\\*\".format(emotion))\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files) * 0.7)]\n",
    "    test = files[-int(len(files) * 0.3):]\n",
    "    return training, test\n",
    "\n",
    "\n",
    "def make_sets():\n",
    "    training_X = []\n",
    "    training_y = []\n",
    "    test_X = []\n",
    "    test_y = []\n",
    "\n",
    "    for emotion in emotions:\n",
    "\n",
    "        training, test = get_files(emotion)\n",
    "\n",
    "        for item in training:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            training_X.append(gray)\n",
    "            training_y.append(emotions.index(emotion))\n",
    "\n",
    "        for item in test:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            test_X.append(gray)\n",
    "            test_y.append(emotions.index(emotion))\n",
    "\n",
    "    return training_X, training_y, test_X, test_y\n",
    "\n",
    "def run_recognizer(clf):\n",
    "    training_X, training_y, test_X, test_y = make_sets()\n",
    "\n",
    "    training_X = np.array(training_X)\n",
    "    training_y = np.array(training_y)\n",
    "\n",
    "    test_X = np.array(test_X)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    training_X = training_X.reshape(training_X.shape[0], 350*350)\n",
    "    test_X = test_X.reshape(test_X.shape[0], 350*350)\n",
    "\n",
    "    clf = clf.fit(training_X, training_y)\n",
    "\n",
    "    predict = clf.predict(test_X)\n",
    "\n",
    "    return accuracy_score(predict, test_y)\n",
    "\n",
    "\n",
    "metascore = []\n",
    "\n",
    "for i in range(0, 3):\n",
    "    correct = run_recognizer(clf)\n",
    "    file.write(\"{} {}\\n\".format(i, correct))\n",
    "    # print(\"{}\".format(i))\n",
    "    metascore.append(correct)\n",
    "\n",
    "metascore = np.array(metascore)\n",
    "\n",
    "print(\"Accuracy: %1.2f%%\" % (metascore.mean()*100))\n",
    "print(\"Margin of Error for More and Less: %1.2f%%\" % (metascore.std()*100))\n",
    "\n",
    "file.write(\"{}\\n\".format(metascore.mean()))\n",
    "file.write(\"{}\\n\".format(metascore.std()))\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etapa 1\n",
      "Score: 0.7265625\n",
      "Matriz de confusao:\n",
      "[[59  3  1  1  0  0  1  0]\n",
      " [ 7  2  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0  0]\n",
      " [ 5  0  0  7  0  0  0  0]\n",
      " [ 3  1  0  1  0  0  0  0]\n",
      " [ 1  0  0  0  0 12  0  0]\n",
      " [ 4  1  0  0  0  0  0  0]\n",
      " [ 2  1  0  0  0  0  0 13]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-72b96c3b8a84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mcorrect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_recognizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Etapa {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-72b96c3b8a84>\u001b[0m in \u001b[0;36mrun_recognizer\u001b[1;34m(clf)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m350\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m350\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    791\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "metascore = []\n",
    "\n",
    "# emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "emotions = [\"happy\", \"surprise\"]\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=500)\n",
    "\n",
    "def get_files(emotion):\n",
    "    files = glob.glob(\"base\\dataset\\\\{}\\\\*\".format(emotion))\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files) * 0.8)]\n",
    "    test = files[-int(len(files) * 0.2):]\n",
    "    return training, test\n",
    "\n",
    "\n",
    "def make_sets():\n",
    "    training_X = []\n",
    "    training_y = []\n",
    "    test_X = []\n",
    "    test_y = []\n",
    "\n",
    "    for emotion in emotions:\n",
    "\n",
    "        training, test = get_files(emotion)\n",
    "\n",
    "        for item in training:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            training_X.append(gray)\n",
    "            training_y.append(emotions.index(emotion))\n",
    "\n",
    "        for item in test:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            test_X.append(gray)\n",
    "            test_y.append(emotions.index(emotion))\n",
    "\n",
    "    training_X = np.array(training_X)\n",
    "    training_y = np.array(training_y)\n",
    "    test_X = np.array(test_X)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    return training_X, training_y, test_X, test_y\n",
    "\n",
    "\n",
    "def run_recognizer(clf):\n",
    "    training_X, training_y, test_X, test_y = make_sets()\n",
    "\n",
    "    training_X = training_X.reshape(training_X.shape[0], 350*350)\n",
    "    test_X = test_X.reshape(test_X.shape[0], 350*350)\n",
    "\n",
    "    clf = clf.fit(training_X, training_y)\n",
    "\n",
    "    predict = clf.predict(test_X)\n",
    "\n",
    "    score = clf.score(test_X, test_y)\n",
    "\n",
    "    cm = confusion_matrix(test_y, predict, labels=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "    accuracy = accuracy_score(predict, test_y)\n",
    "\n",
    "    return accuracy, score, cm\n",
    "\n",
    "\n",
    "for i in range(0, 3):\n",
    "\n",
    "    correct, score, cm = run_recognizer(clf)\n",
    "\n",
    "    print(\"Etapa {}\".format(i+1))\n",
    "\n",
    "    print(\"Score: {}\".format(score))\n",
    "\n",
    "    print(\"Matriz de confusao:\")\n",
    "    print(cm)\n",
    "\n",
    "    metascore.append(correct)\n",
    "\n",
    "metascore = np.array(metascore)\n",
    "\n",
    "print(\"Acuracy: %1.2f%%\" % (metascore.mean()*100))\n",
    "print(\"Margin of Error for More and Less: %1.2f%%\" % (metascore.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etapa 1\n",
      "Score: 0.7265625\n",
      "Matriz de confusao:\n",
      "[[65  0  0  0  0  0  0  0]\n",
      " [ 8  0  0  0  0  1  0  0]\n",
      " [ 3  0  0  0  0  0  0  0]\n",
      " [ 7  1  0  4  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  1]\n",
      " [ 2  0  0  0  0 11  0  0]\n",
      " [ 5  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "metascore = []\n",
    "\n",
    "emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "# emotions = [\"happy\", \"surprise\"]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500, max_features=.3)\n",
    "\n",
    "def get_files(emotion):\n",
    "    files = glob.glob(\"base\\dataset\\\\{}\\\\*\".format(emotion))\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files) * 0.8)]\n",
    "    test = files[-int(len(files) * 0.2):]\n",
    "    return training, test\n",
    "\n",
    "\n",
    "def make_sets():\n",
    "    training_X = []\n",
    "    training_y = []\n",
    "    test_X = []\n",
    "    test_y = []\n",
    "\n",
    "    for emotion in emotions:\n",
    "\n",
    "        training, test = get_files(emotion)\n",
    "\n",
    "        for item in training:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            training_X.append(gray)\n",
    "            training_y.append(emotions.index(emotion))\n",
    "\n",
    "        for item in test:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            test_X.append(gray)\n",
    "            test_y.append(emotions.index(emotion))\n",
    "\n",
    "    training_X = np.array(training_X)\n",
    "    training_y = np.array(training_y)\n",
    "    test_X = np.array(test_X)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    return training_X, training_y, test_X, test_y\n",
    "\n",
    "\n",
    "def run_recognizer(clf):\n",
    "    training_X, training_y, test_X, test_y = make_sets()\n",
    "\n",
    "    training_X = training_X.reshape(training_X.shape[0], 350*350)\n",
    "    test_X = test_X.reshape(test_X.shape[0], 350*350)\n",
    "\n",
    "    clf = clf.fit(training_X, training_y)\n",
    "\n",
    "    predict = clf.predict(test_X)\n",
    "\n",
    "    score = clf.score(test_X, test_y)\n",
    "\n",
    "    cm = confusion_matrix(test_y, predict, labels=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "    accuracy = accuracy_score(predict, test_y)\n",
    "\n",
    "    return accuracy, score, cm\n",
    "\n",
    "\n",
    "for i in range(0, 3):\n",
    "\n",
    "    correct, score, cm = run_recognizer(clf)\n",
    "\n",
    "    print(\"Etapa {}\".format(i+1))\n",
    "\n",
    "    print(\"Score: {}\".format(score))\n",
    "\n",
    "    print(\"Matriz de confusao:\")\n",
    "    print(cm)\n",
    "\n",
    "    metascore.append(correct)\n",
    "\n",
    "metascore = np.array(metascore)\n",
    "\n",
    "print(\"Acuracy: %1.2f%%\" % (metascore.mean()*100))\n",
    "print(\"Margin of Error for More and Less: %1.2f%%\" % (metascore.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etapa 1\n",
      "Score: 0.9655172413793104\n",
      "\n",
      "Matriz de confusao:\n",
      "[[13  0  0  0  0  0  0  0]\n",
      " [ 1 15  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "\n",
      "Best Score:\n",
      "0.99173553719\n",
      "\n",
      "Best Params:\n",
      "{'criterion': 'gini', 'max_depth': 4, 'max_features': 'auto', 'min_samples_split': 20, 'n_estimators': 200}\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        13\n",
      "          1       1.00      0.94      0.97        16\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "Etapa 2\n",
      "Score: 1.0\n",
      "\n",
      "Matriz de confusao:\n",
      "[[13  0  0  0  0  0  0  0]\n",
      " [ 0 16  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "\n",
      "Best Score:\n",
      "0.99173553719\n",
      "\n",
      "Best Params:\n",
      "{'criterion': 'gini', 'max_depth': 4, 'max_features': 'auto', 'min_samples_split': 10, 'n_estimators': 500}\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       1.00      1.00      1.00        29\n",
      "\n",
      "Etapa 3\n",
      "Score: 0.896551724137931\n",
      "\n",
      "Matriz de confusao:\n",
      "[[12  1  0  0  0  0  0  0]\n",
      " [ 2 14  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "\n",
      "Best Score:\n",
      "0.98347107438\n",
      "\n",
      "Best Params:\n",
      "{'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'min_samples_split': 30, 'n_estimators': 500}\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        13\n",
      "          1       1.00      0.94      0.97        16\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "\n",
      "Acuracy: 95.40%\n",
      "Margin of Error for More and Less: 4.30%\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "metascore = []\n",
    "\n",
    "# emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "emotions = [\"happy\", \"surprise\"]\n",
    "\n",
    "clf = RandomForestClassifier(max_features=500)\n",
    "\n",
    "def get_files(emotion):\n",
    "    files = glob.glob(\"base\\dataset\\\\{}\\\\*\".format(emotion))\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files) * 0.8)]\n",
    "    test = files[-int(len(files) * 0.2):]\n",
    "    return training, test\n",
    "\n",
    "\n",
    "def make_sets():\n",
    "    training_X = []\n",
    "    training_y = []\n",
    "    test_X = []\n",
    "    test_y = []\n",
    "\n",
    "    for emotion in emotions:\n",
    "\n",
    "        training, test = get_files(emotion)\n",
    "\n",
    "        for item in training:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            training_X.append(gray)\n",
    "            training_y.append(emotions.index(emotion))\n",
    "\n",
    "        for item in test:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            test_X.append(gray)\n",
    "            test_y.append(emotions.index(emotion))\n",
    "\n",
    "    training_X = np.array(training_X)\n",
    "    training_y = np.array(training_y)\n",
    "    test_X = np.array(test_X)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    return training_X, training_y, test_X, test_y\n",
    "\n",
    "\n",
    "def run_recognizer(clf):\n",
    "    training_X, training_y, test_X, test_y = make_sets()\n",
    "\n",
    "    training_X = training_X.reshape(training_X.shape[0], 350*350)\n",
    "    test_X = test_X.reshape(test_X.shape[0], 350*350)\n",
    "\n",
    "    clf = clf.fit(training_X, training_y)\n",
    "\n",
    "    predict = clf.predict(test_X)\n",
    "\n",
    "    score = clf.score(test_X, test_y)\n",
    "\n",
    "    cm = confusion_matrix(test_y, predict, labels=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "    accuracy = accuracy_score(predict, test_y)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [200, 500, 700],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'max_depth': [4, 5, 6, 7, 8],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'min_samples_split': [10, 20, 30, 40, 50]\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5)\n",
    "    grid.fit(training_X, training_y)\n",
    "\n",
    "    y_true, y_pred = test_y, grid.predict(test_X)\n",
    "\n",
    "    bs = grid.best_score_\n",
    "    bp = grid.best_params_\n",
    "    cr = classification_report(y_true, y_pred)  # isso também mostra o precision, recall e f1-score\n",
    "\n",
    "\n",
    "    return accuracy, score, cm, bs, bp, cr\n",
    "\n",
    "\n",
    "for i in range(0, 3):\n",
    "\n",
    "    correct, score, cm, bs, bp, cr = run_recognizer(clf)\n",
    "\n",
    "    print(\"Etapa {}\".format(i+1))\n",
    "\n",
    "    print(\"Score: {}\".format(score))\n",
    "\n",
    "    print(\"\\nMatriz de confusao:\")\n",
    "    print(cm)\n",
    "\n",
    "    print(\"\\nBest Score:\")\n",
    "    print(bs)\n",
    "\n",
    "    print(\"\\nBest Params:\")\n",
    "    print(bp)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(cr)\n",
    "\n",
    "    metascore.append(correct)\n",
    "\n",
    "metascore = np.array(metascore)\n",
    "\n",
    "print(\"\\nAcuracy: %1.2f%%\" % (metascore.mean()*100))\n",
    "print(\"Margin of Error for More and Less: %1.2f%%\" % (metascore.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Etapa: \u001b[0m1\n",
      "\n",
      "\u001b[1m Score: \u001b[1;34m 1.0 \n",
      "\u001b[0m\n",
      "\u001b[1m Matriz de confusao:\n",
      "\n",
      "\u001b[0m [[13  0  0  0  0  0  0  0]\n",
      " [ 0 16  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]] \n",
      "\n",
      "\u001b[1m Best Score: \u001b[1;34m 0.9834710743801653\n",
      "\u001b[0m\n",
      "\u001b[1m Best Params:\n",
      "\n",
      "\u001b[0m {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 6, 'max_features': 51, 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 200}\n",
      "\n",
      "\u001b[1m Classification Report:\n",
      "\n",
      "\u001b[0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       1.00      1.00      1.00        29\n",
      "\n",
      "\u001b[1m Etapa: \u001b[0m2\n",
      "\n",
      "\u001b[1m Score: \u001b[1;34m 0.9310344827586207 \n",
      "\u001b[0m\n",
      "\u001b[1m Matriz de confusao:\n",
      "\n",
      "\u001b[0m [[13  0  0  0  0  0  0  0]\n",
      " [ 2 14  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]] \n",
      "\n",
      "\u001b[1m Best Score: \u001b[1;34m 0.9669421487603306\n",
      "\u001b[0m\n",
      "\u001b[1m Best Params:\n",
      "\n",
      "\u001b[0m {'bootstrap': True, 'criterion': 'gini', 'max_depth': 5, 'max_features': 83, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 200}\n",
      "\n",
      "\u001b[1m Classification Report:\n",
      "\n",
      "\u001b[0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93        13\n",
      "          1       1.00      0.88      0.93        16\n",
      "\n",
      "avg / total       0.94      0.93      0.93        29\n",
      "\n",
      "\u001b[1m Etapa: \u001b[0m3\n",
      "\n",
      "\u001b[1m Score: \u001b[1;34m 0.9310344827586207 \n",
      "\u001b[0m\n",
      "\u001b[1m Matriz de confusao:\n",
      "\n",
      "\u001b[0m [[13  0  0  0  0  0  0  0]\n",
      " [ 2 14  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]] \n",
      "\n",
      "\u001b[1m Best Score: \u001b[1;34m 0.9834710743801653\n",
      "\u001b[0m\n",
      "\u001b[1m Best Params:\n",
      "\n",
      "\u001b[0m {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 4, 'min_samples_leaf': 14, 'min_samples_split': 17, 'n_estimators': 600}\n",
      "\n",
      "\u001b[1m Classification Report:\n",
      "\n",
      "\u001b[0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.85      0.88        13\n",
      "          1       0.88      0.94      0.91        16\n",
      "\n",
      "avg / total       0.90      0.90      0.90        29\n",
      "\n",
      "\n",
      "\u001b[1m Acuracy: \u001b[1;34m 95.40%\n",
      "\u001b[1m Margin of Error for More and Less: \u001b[1;34m 3.25%\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "metascore = []\n",
    "\n",
    "# emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "emotions = [\"happy\", \"surprise\"]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "\n",
    "\n",
    "def get_files(emotion):\n",
    "    files = glob.glob(\"base\\dataset\\\\{}\\\\*\".format(emotion))\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files) * 0.8)]\n",
    "    test = files[-int(len(files) * 0.2):]\n",
    "    return training, test\n",
    "\n",
    "\n",
    "def make_sets():\n",
    "    training_X = []\n",
    "    training_y = []\n",
    "    test_X = []\n",
    "    test_y = []\n",
    "\n",
    "    for emotion in emotions:\n",
    "\n",
    "        training, test = get_files(emotion)\n",
    "\n",
    "        for item in training:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            training_X.append(gray)\n",
    "            training_y.append(emotions.index(emotion))\n",
    "\n",
    "        for item in test:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            test_X.append(gray)\n",
    "            test_y.append(emotions.index(emotion))\n",
    "\n",
    "    training_X = np.array(training_X)\n",
    "    training_y = np.array(training_y)\n",
    "    test_X = np.array(test_X)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    return training_X, training_y, test_X, test_y\n",
    "\n",
    "\n",
    "def run_recognizer(clf):\n",
    "    training_X, training_y, test_X, test_y = make_sets()\n",
    "\n",
    "    training_X = training_X.reshape(training_X.shape[0], 350 * 350)\n",
    "    test_X = test_X.reshape(test_X.shape[0], 350 * 350)\n",
    "\n",
    "    clf = clf.fit(training_X, training_y)\n",
    "\n",
    "    predict = clf.predict(test_X)\n",
    "\n",
    "    score = clf.score(test_X, test_y)\n",
    "\n",
    "    cm = confusion_matrix(test_y, predict, labels=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "    accuracy = accuracy_score(predict, test_y)\n",
    "\n",
    "    param_dist = {\"max_depth\" :  [3, 4, 5, 6, 7],\n",
    "                  \"max_features\" : sp_randint(2, 100),\n",
    "                  \"min_samples_split\" : sp_randint(8, 30),\n",
    "                  \"min_samples_leaf\" : sp_randint(5, 20),\n",
    "                  \"n_estimators\" : [100, 200, 300, 400, 500, 600],\n",
    "                  \"bootstrap\" : [True, False],\n",
    "                  \"criterion\" : [\"gini\", \"entropy\"]\n",
    "                  }\n",
    "\n",
    "    grid = RandomizedSearchCV(estimator=clf, param_distributions = param_dist, n_iter=100)\n",
    "    grid.fit(training_X, training_y)\n",
    "\n",
    "    y_true, y_pred = test_y, grid.predict(test_X)\n",
    "\n",
    "    bs = grid.best_score_\n",
    "    bp = grid.best_params_\n",
    "    cr = classification_report(y_true, y_pred)  # isso também mostra o precision, recall e f1-score\n",
    "\n",
    "    return accuracy, score, cm, bs, bp, cr\n",
    "\n",
    "\n",
    "for i in range(0, 3):\n",
    "    correct, score, cm, bs, bp, cr = run_recognizer(clf)\n",
    "\n",
    "    print('\\033[1m Etapa: ' + '\\033[0m{}\\n'.format(i + 1))\n",
    "\n",
    "    print ('\\033[1m Score: ' + '\\033[1;34m {} \\n'.format(score) + '\\033[0m')\n",
    "\n",
    "    print('\\033[1m Matriz de confusao:\\n\\n' + '\\033[0m {} \\n'.format(cm))\n",
    "\n",
    "    print('\\033[1m Best Score: ' + '\\033[1;34m {}\\n'.format(bs) + '\\033[0m')\n",
    "\n",
    "    print('\\033[1m Best Params:\\n\\n' + '\\033[0m {}\\n'.format(bp))\n",
    "\n",
    "    print('\\033[1m Classification Report:\\n\\n' + '\\033[0m {}'.format(cr))\n",
    "\n",
    "    metascore.append(correct)\n",
    "\n",
    "metascore = np.array(metascore)\n",
    "\n",
    "print(\"\\n\\033[1m Acuracy: \\033[1;34m %1.2f%% \\033[0m\" % (metascore.mean() * 100))\n",
    "print(\"\\033[1m Margin of Error for More and Less: \\033[1;34m %1.2f%%\" % (metascore.std() * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Etapa: \u001b[0m1\n",
      "\n",
      "\u001b[1m Score: \u001b[1;34m 0.896551724137931 \n",
      "\u001b[0m\n",
      "\u001b[1m Matriz de confusao:\n",
      "\n",
      "\u001b[0m [[11  2  0  0  0  0  0  0]\n",
      " [ 1 15  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]] \n",
      "\n",
      "\u001b[1m Best Score: \u001b[1;34m 0.9834710743801653\n",
      "\u001b[0m\n",
      "\u001b[1m Best Params:\n",
      "\n",
      "\u001b[0m {'criterion': 'mse', 'max_depth': 3, 'max_features': 52, 'min_samples_leaf': 6, 'min_samples_split': 28, 'n_estimators': 600}\n",
      "\n",
      "\u001b[1m Classification Report:\n",
      "\n",
      "\u001b[0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       1.00      1.00      1.00        29\n",
      "\n",
      "\u001b[1m Etapa: \u001b[0m2\n",
      "\n",
      "\u001b[1m Score: \u001b[1;34m 0.896551724137931 \n",
      "\u001b[0m\n",
      "\u001b[1m Matriz de confusao:\n",
      "\n",
      "\u001b[0m [[12  1  0  0  0  0  0  0]\n",
      " [ 2 14  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]] \n",
      "\n",
      "\u001b[1m Best Score: \u001b[1;34m 0.9917355371900827\n",
      "\u001b[0m\n",
      "\u001b[1m Best Params:\n",
      "\n",
      "\u001b[0m {'criterion': 'mae', 'max_depth': 3, 'max_features': 73, 'min_samples_leaf': 5, 'min_samples_split': 13, 'n_estimators': 200}\n",
      "\n",
      "\u001b[1m Classification Report:\n",
      "\n",
      "\u001b[0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96        13\n",
      "          1       1.00      0.94      0.97        16\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "\u001b[1m Etapa: \u001b[0m3\n",
      "\n",
      "\u001b[1m Score: \u001b[1;34m 0.9655172413793104 \n",
      "\u001b[0m\n",
      "\u001b[1m Matriz de confusao:\n",
      "\n",
      "\u001b[0m [[12  1  0  0  0  0  0  0]\n",
      " [ 0 16  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]] \n",
      "\n",
      "\u001b[1m Best Score: \u001b[1;34m 0.9752066115702479\n",
      "\u001b[0m\n",
      "\u001b[1m Best Params:\n",
      "\n",
      "\u001b[0m {'criterion': 'mse', 'max_depth': 4, 'max_features': 5, 'min_samples_leaf': 10, 'min_samples_split': 19, 'n_estimators': 400}\n",
      "\n",
      "\u001b[1m Classification Report:\n",
      "\n",
      "\u001b[0m              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96        13\n",
      "          1       0.94      1.00      0.97        16\n",
      "\n",
      "avg / total       0.97      0.97      0.97        29\n",
      "\n",
      "\n",
      "\u001b[1m Acuracy: \u001b[1;34m 91.95% \u001b[0m\n",
      "\u001b[1m Margin of Error for More and Less: \u001b[1;34m 3.25%\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "metascore = []\n",
    "\n",
    "# emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "emotions = [\"happy\", \"surprise\"]\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=500)\n",
    "\n",
    "\n",
    "def get_files(emotion):\n",
    "    files = glob.glob(\"base\\dataset\\\\{}\\\\*\".format(emotion))\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files) * 0.8)]\n",
    "    test = files[-int(len(files) * 0.2):]\n",
    "    return training, test\n",
    "\n",
    "\n",
    "def make_sets():\n",
    "    training_X = []\n",
    "    training_y = []\n",
    "    test_X = []\n",
    "    test_y = []\n",
    "\n",
    "    for emotion in emotions:\n",
    "\n",
    "        training, test = get_files(emotion)\n",
    "\n",
    "        for item in training:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            training_X.append(gray)\n",
    "            training_y.append(emotions.index(emotion))\n",
    "\n",
    "        for item in test:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            test_X.append(gray)\n",
    "            test_y.append(emotions.index(emotion))\n",
    "\n",
    "    training_X = np.array(training_X)\n",
    "    training_y = np.array(training_y)\n",
    "    test_X = np.array(test_X)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    return training_X, training_y, test_X, test_y\n",
    "\n",
    "\n",
    "def run_recognizer(clf):\n",
    "    training_X, training_y, test_X, test_y = make_sets()\n",
    "\n",
    "    training_X = training_X.reshape(training_X.shape[0], 350 * 350)\n",
    "    test_X = test_X.reshape(test_X.shape[0], 350 * 350)\n",
    "\n",
    "    clf = clf.fit(training_X, training_y)\n",
    "\n",
    "    predict = clf.predict(test_X)\n",
    "\n",
    "    score = clf.score(test_X, test_y)\n",
    "\n",
    "    cm = confusion_matrix(test_y, predict, labels=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "    accuracy = accuracy_score(predict, test_y)\n",
    "\n",
    "    param_dist = {\"max_depth\" :  [3, 4, 5, 6, 7],\n",
    "                  \"max_features\" : sp_randint(2, 100),\n",
    "                  \"min_samples_split\" : sp_randint(8, 30),\n",
    "                  \"min_samples_leaf\" : sp_randint(5, 20),\n",
    "                  \"n_estimators\" : [100, 200, 300, 400, 500, 600],\n",
    "                  \"criterion\" : [\"mae\", \"mse\"]\n",
    "                  }\n",
    "\n",
    "    grid = RandomizedSearchCV(estimator=clf, param_distributions = param_dist, n_iter=100)\n",
    "    grid.fit(training_X, training_y)\n",
    "\n",
    "    y_true, y_pred = test_y, grid.predict(test_X)\n",
    "\n",
    "    bs = grid.best_score_\n",
    "    bp = grid.best_params_\n",
    "    cr = classification_report(y_true, y_pred)  # isso também mostra o precision, recall e f1-score\n",
    "\n",
    "    return accuracy, score, cm, bs, bp, cr\n",
    "\n",
    "\n",
    "for i in range(0, 3):\n",
    "    correct, score, cm, bs, bp, cr = run_recognizer(clf)\n",
    "\n",
    "    print('\\033[1m Etapa: ' + '\\033[0m{}\\n'.format(i + 1))\n",
    "\n",
    "    print ('\\033[1m Score: ' + '\\033[1;34m {} \\n'.format(score) + '\\033[0m')\n",
    "\n",
    "    print('\\033[1m Matriz de confusao:\\n\\n' + '\\033[0m {} \\n'.format(cm))\n",
    "\n",
    "    print('\\033[1m Best Score: ' + '\\033[1;34m {}\\n'.format(bs) + '\\033[0m')\n",
    "\n",
    "    print('\\033[1m Best Params:\\n\\n' + '\\033[0m {}\\n'.format(bp))\n",
    "\n",
    "    print('\\033[1m Classification Report:\\n\\n' + '\\033[0m {}'.format(cr))\n",
    "\n",
    "    metascore.append(correct)\n",
    "\n",
    "metascore = np.array(metascore)\n",
    "\n",
    "print(\"\\n\\033[1m Acuracy: \\033[1;34m %1.2f%% \\033[0m\" % (metascore.mean() * 100))\n",
    "print(\"\\033[1m Margin of Error for More and Less: \\033[1;34m %1.2f%%\" % (metascore.std() * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA em um Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-fbb909c2e987>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[0mcorrect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_recognizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\033[1m Etapa: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\033[0m{}\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-fbb909c2e987>\u001b[0m in \u001b[0;36mrun_recognizer\u001b[1;34m(clf)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "metascore = []\n",
    "\n",
    "emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "# emotions = [\"happy\", \"surprise\"]\n",
    "\n",
    "\n",
    "def get_files(emotion):\n",
    "    files = glob.glob(\"base\\dataset\\\\{}\\\\*\".format(emotion))\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files) * 0.8)]\n",
    "    test = files[-int(len(files) * 0.2):]\n",
    "    return training, test\n",
    "\n",
    "\n",
    "def make_sets():\n",
    "    training_X = []\n",
    "    training_y = []\n",
    "    test_X = []\n",
    "    test_y = []\n",
    "\n",
    "    for emotion in emotions:\n",
    "\n",
    "        training, test = get_files(emotion)\n",
    "\n",
    "        for item in training:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            training_X.append(gray)\n",
    "            training_y.append(emotions.index(emotion))\n",
    "\n",
    "        for item in test:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            test_X.append(gray)\n",
    "            test_y.append(emotions.index(emotion))\n",
    "\n",
    "    training_X = np.array(training_X)\n",
    "    training_y = np.array(training_y)\n",
    "    test_X = np.array(test_X)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    return training_X, training_y, test_X, test_y\n",
    "\n",
    "\n",
    "def run_recognizer(clf):\n",
    "    training_X, training_y, test_X, test_y = make_sets()\n",
    "\n",
    "    training_X = training_X.reshape(training_X.shape[0], 350 * 350)\n",
    "    test_X = test_X.reshape(test_X.shape[0], 350 * 350)\n",
    "\n",
    "    clf = clf.fit(training_X, training_y)\n",
    "\n",
    "    predict = clf.predict(test_X)\n",
    "\n",
    "    score = clf.score(test_X, test_y)\n",
    "\n",
    "    cm = confusion_matrix(test_y, predict, labels=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "    accuracy = accuracy_score(predict, test_y)\n",
    "\n",
    "    # print(clf.get_params().keys())\n",
    "\n",
    "    param_dist = {\"randomforestclassifier__max_depth\": [5, 6, 7],\n",
    "                  \"randomforestclassifier__max_features\": [.1, .25, .5, .75, 1. ],\n",
    "                  \"randomforestclassifier__n_estimators\": [400, 500, 600],\n",
    "                  \"randomforestclassifier__bootstrap\" :  [True, False],\n",
    "                  \"randomforestclassifier__n_jobs\" : [50, 100, 200],\n",
    "                  \"randomforestclassifier__criterion\": [\"gini\", \"entropy\"],\n",
    "                  \"pca__svd_solver\" : [\"full\",\"randomized\"],\n",
    "                  \"pca__n_components\" : [200, 500, 700]\n",
    "                  }\n",
    "\n",
    "    grid = RandomizedSearchCV(estimator=clf, param_distributions=param_dist, n_iter=100)\n",
    "    grid.fit(training_X, training_y)\n",
    "\n",
    "    y_true, y_pred = test_y, grid.predict(test_X)\n",
    "\n",
    "    bs = grid.best_score_\n",
    "    bp = grid.best_params_\n",
    "    cr = classification_report(y_true, y_pred)  # isso também mostra o precision, recall e f1-score\n",
    "\n",
    "    return accuracy, score, cm, bs, bp, cr\n",
    "\n",
    "clf = make_pipeline(PCA(copy=True,\n",
    "                        iterated_power='auto',\n",
    "                        n_components=2000,\n",
    "                        random_state=sp_randint(2, 20),\n",
    "                        svd_solver='full',\n",
    "                        whiten=False\n",
    "                        ),\n",
    "                    RandomForestClassifier(bootstrap=False,\n",
    "                                           criterion='entropy',\n",
    "                                           max_depth=6,\n",
    "                                           max_features=51,\n",
    "                                           min_samples_leaf=5,\n",
    "                                           min_samples_split=16,\n",
    "                                           n_estimators=200\n",
    "                                          )\n",
    "                    )\n",
    "\n",
    "\n",
    "# GradientBoostingClassifier(n_estimators=500)\n",
    "# ExtraTreesClassifier(n_estimators=500)\n",
    "\n",
    "\n",
    "for i in range(0, 3):\n",
    "    correct, score, cm, bs, bp, cr = run_recognizer(clf)\n",
    "\n",
    "    print('\\033[1m Etapa: ' + '\\033[0m{}\\n'.format(i + 1))\n",
    "\n",
    "    print ('\\033[1m Score: ' + '\\033[1;34m {} \\n'.format(score) + '\\033[0m')\n",
    "\n",
    "    print('\\033[1m Matriz de confusao:\\n\\n' + '\\033[0m {} \\n'.format(cm))\n",
    "\n",
    "    print('\\033[1m Best Score: ' + '\\033[1;34m {}\\n'.format(bs) + '\\033[0m')\n",
    "\n",
    "    print('\\033[1m Best Params:\\n\\n' + '\\033[0m {}\\n'.format(bp))\n",
    "\n",
    "    print('\\033[1m Classification Report:\\n\\n' + '\\033[0m {}'.format(cr))\n",
    "\n",
    "    metascore.append(correct)\n",
    "\n",
    "metascore = np.array(metascore)\n",
    "\n",
    "print(\"\\n\\033[1m Acuracy: \\033[1;34m %1.2f%% \\033[0m\" % (metascore.mean() * 100))\n",
    "print(\"\\033[1m Margin of Error for More and Less: \\033[1;34m %1.2f%%\" % (metascore.std() * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['memory', 'steps', 'pca', 'randomforestclassifier', 'pca__copy', 'pca__iterated_power', 'pca__n_components', 'pca__random_state', 'pca__svd_solver', 'pca__tol', 'pca__whiten', 'randomforestclassifier__bootstrap', 'randomforestclassifier__class_weight', 'randomforestclassifier__criterion', 'randomforestclassifier__max_depth', 'randomforestclassifier__max_features', 'randomforestclassifier__max_leaf_nodes', 'randomforestclassifier__min_impurity_decrease', 'randomforestclassifier__min_impurity_split', 'randomforestclassifier__min_samples_leaf', 'randomforestclassifier__min_samples_split', 'randomforestclassifier__min_weight_fraction_leaf', 'randomforestclassifier__n_estimators', 'randomforestclassifier__n_jobs', 'randomforestclassifier__oob_score', 'randomforestclassifier__random_state', 'randomforestclassifier__verbose', 'randomforestclassifier__warm_start'])\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "metascore1 = []\n",
    "metascore2 = []\n",
    "metascore3 = []\n",
    "metascore4 = []\n",
    "\n",
    "# emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "emotions = [\"happy\", \"surprise\"]\n",
    "\n",
    "\n",
    "def get_param_dist(label):\n",
    "    if (label == 'Random Forest'):\n",
    "        param_dist = {\"randomforestclassifier__max_depth\": [3, 4, 5, 6, 7],\n",
    "                      \"randomforestclassifier__max_features\": [.1, .25, .5, .75, 1.],\n",
    "                      \"randomforestclassifier__max_leaf_nodes\": sp_randint(2, 100),\n",
    "                      \"randomforestclassifier__min_samples_split\": sp_randint(8, 30),\n",
    "                      \"randomforestclassifier__min_samples_leaf\": sp_randint(5, 20),\n",
    "                      \"randomforestclassifier__n_estimators\": [100, 200, 300, 400, 500, 600],\n",
    "                      \"randomforestclassifier__bootstrap\": [True, False],\n",
    "                      \"randomforestclassifier__n_jobs\": [5, 20, 50, 100, 200],\n",
    "                      \"randomforestclassifier__criterion\": [\"gini\", \"entropy\"],\n",
    "                      \"pca__iterated_power\": [\"auto\"],\n",
    "                      \"pca__svd_solver\": [\"full\", \"randomized\"],\n",
    "                      \"pca__whiten\": [True, False],\n",
    "                      \"pca__random_state\": sp_randint(2, 20),\n",
    "                      \"pca__n_components\": [200, 500, 700, 1000, 2000]\n",
    "                      }\n",
    "    elif(label == 'Extra Trees'):\n",
    "\n",
    "        param_dist = {\"extratreesclassifier__n_estimators\": [100, 200, 300, 400, 500, 600],\n",
    "                      \"pca__whiten\": [True, False],\n",
    "                      \"extratreesclassifier__max_features\": [.1, .25, .5, .75, 1.],\n",
    "                      \"extratreesclassifier__min_samples_split\": sp_randint(8, 30),\n",
    "                      \"pca__iterated_power\": [\"auto\"],\n",
    "                      \"pca__random_state\": sp_randint(2, 20),\n",
    "                      \"pca__svd_solver\": [\"full\", \"randomized\"],\n",
    "                      \"extratreesclassifier__bootstrap\": [True, False],\n",
    "                      \"extratreesclassifier__n_jobs\": [5, 20, 50, 100, 200],\n",
    "                      \"extratreesclassifier__max_leaf_nodes\": sp_randint(2, 100),\n",
    "                      \"extratreesclassifier__criterion\": [\"gini\", \"entropy\"],\n",
    "                      \"pca__n_components\": [200, 500, 700, 1000, 2000],\n",
    "                      \"extratreesclassifier__min_samples_leaf\": sp_randint(5, 20),\n",
    "                      \"extratreesclassifier__max_depth\": [3, 4, 5, 6, 7]\n",
    "                      }\n",
    "    elif(label == 'Gradient Boosting'):\n",
    "\n",
    "        param_dist = {\"pca__whiten\": [True, False],\n",
    "                      \"gradientboostingclassifier__min_samples_leaf\": sp_randint(5, 20),\n",
    "                      \"gradientboostingclassifier__criterion\": [],\n",
    "                      \"gradientboostingclassifier__max_leaf_nodes\": sp_randint(2, 100),\n",
    "                      \"pca__iterated_power\": [\"auto\"],\n",
    "                      \"gradientboostingclassifier__max_features\": [.1, .25, .5, .75, 1.],\n",
    "                      \"gradientboostingclassifier__n_estimators\": [100, 200, 300, 400, 500, 600],\n",
    "                      \"pca__svd_solver\": [\"full\", \"randomized\"],\n",
    "                      \"pca__n_components\": [200, 500, 700, 1000, 2000],\n",
    "                      \"gradientboostingclassifier__max_depth\": [3, 4, 5, 6, 7]\n",
    "                      }\n",
    "    else:\n",
    "        param_dist = {}\n",
    "\n",
    "    return param_dist\n",
    "\n",
    "def get_files(emotion):\n",
    "    files = glob.glob(\"base\\dataset\\\\{}\\\\*\".format(emotion))\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files) * 0.8)]\n",
    "    test = files[-int(len(files) * 0.2):]\n",
    "    return training, test\n",
    "\n",
    "\n",
    "def make_sets():\n",
    "    training_X = []\n",
    "    training_y = []\n",
    "    test_X = []\n",
    "    test_y = []\n",
    "\n",
    "    for emotion in emotions:\n",
    "\n",
    "        training, test = get_files(emotion)\n",
    "\n",
    "        for item in training:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            training_X.append(gray)\n",
    "            training_y.append(emotions.index(emotion))\n",
    "\n",
    "        for item in test:\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            test_X.append(gray)\n",
    "            test_y.append(emotions.index(emotion))\n",
    "\n",
    "    training_X = np.array(training_X)\n",
    "    training_y = np.array(training_y)\n",
    "    test_X = np.array(test_X)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    return training_X, training_y, test_X, test_y\n",
    "\n",
    "\n",
    "def run_recognizer(clf, label):\n",
    "    training_X, training_y, test_X, test_y = make_sets()\n",
    "\n",
    "    training_X = training_X.reshape(training_X.shape[0], 350 * 350)\n",
    "    test_X = test_X.reshape(test_X.shape[0], 350 * 350)\n",
    "\n",
    "    clf = clf.fit(training_X, training_y)\n",
    "\n",
    "    predict = clf.predict(test_X)\n",
    "\n",
    "    score = clf.score(test_X, test_y)\n",
    "\n",
    "    cm = confusion_matrix(test_y, predict, labels=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "    accuracy = accuracy_score(predict, test_y)\n",
    "\n",
    "    print(clf.get_params().keys())\n",
    "\n",
    "    param_dist = get_param_dist(label)\n",
    "\n",
    "    grid = RandomizedSearchCV(estimator=clf, param_distributions=param_dist, n_iter=100)\n",
    "    grid.fit(training_X, training_y)\n",
    "\n",
    "    y_true, y_pred = test_y, grid.predict(test_X)\n",
    "\n",
    "    bs = grid.best_score_\n",
    "    bp = grid.best_params_\n",
    "    cr = classification_report(y_true, y_pred)  # isso também mostra o precision, recall e f1-score\n",
    "\n",
    "    return accuracy, score, cm, bs, bp, cr\n",
    "\n",
    "\n",
    "clf1 = make_pipeline(PCA(copy=True,\n",
    "                         iterated_power='auto',\n",
    "                         n_components=2000,\n",
    "                         random_state=sp_randint(2, 20),\n",
    "                         svd_solver='full',\n",
    "                         whiten=False\n",
    "                         ),\n",
    "                     RandomForestClassifier(n_estimators=700, n_jobs=-1)\n",
    "                     )\n",
    "\n",
    "clf2 = make_pipeline(PCA(copy=True,\n",
    "                         iterated_power='auto',\n",
    "                         n_components=2000,\n",
    "                         random_state=sp_randint(2, 20),\n",
    "                         svd_solver='full',\n",
    "                         whiten=False\n",
    "                         ),\n",
    "                     ExtraTreesClassifier(n_estimators=500)\n",
    "                     )\n",
    "\n",
    "clf3 = make_pipeline(PCA(copy=True,\n",
    "                         iterated_power='auto',\n",
    "                         n_components=2000,\n",
    "                         random_state=sp_randint(2, 20),\n",
    "                         svd_solver='full',\n",
    "                         whiten=False\n",
    "                         ),\n",
    "                     GradientBoostingClassifier(n_estimators=500)\n",
    "                     )\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('rf', clf1), ('et', clf2), ('gb', clf3)], voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Random Forest', 'Extra Trees', 'Gradient Boosting', 'Voting']):\n",
    "\n",
    "    for i in range(0, 3):\n",
    "        correct, score, cm, bs, bp, cr = run_recognizer(clf, label)\n",
    "\n",
    "        print('\\033[1m Etapa: ' + '\\033[0m{}\\n'.format(i + 1))\n",
    "\n",
    "        print ('\\033[1m Score: ' + '\\033[1;34m {} \\n'.format(score) + '\\033[0m')\n",
    "\n",
    "        print('\\033[1m Matriz de confusao:\\n\\n' + '\\033[0m {} \\n'.format(cm))\n",
    "\n",
    "        print('\\033[1m Best Score: ' + '\\033[1;34m {}\\n'.format(bs) + '\\033[0m')\n",
    "\n",
    "        print('\\033[1m Best Params:\\n\\n' + '\\033[0m {}\\n'.format(bp))\n",
    "\n",
    "        print('\\033[1m Classification Report:\\n\\n' + '\\033[0m {}'.format(cr))\n",
    "\n",
    "        if(label == 'Random Forest'):\n",
    "            metascore1.append(correct)\n",
    "        elif(label == 'Extra Trees'):\n",
    "            metascore2.append(correct)\n",
    "        elif(label == 'Gradient Boosting'):\n",
    "            metascore3.append(correct)\n",
    "        else:\n",
    "            metascore4.append(correct)\n",
    "\n",
    "metascore1 = np.array(metascore1)\n",
    "metascore2 = np.array(metascore2)\n",
    "metascore3 = np.array(metascore3)\n",
    "metascore4 = np.array(metascore4)\n",
    "\n",
    "print(\"\\n\\033[1m Acuracy the \\033[1;31m Random Forest\\033[1m: \\033[1;34m %1.2f%% \\033[0m\" % (metascore1.mean() * 100))\n",
    "print(\"\\033[1m Margin of Error for More and Less: \\033[1;34m %1.2f%% \\n\" % (metascore1.std() * 100))\n",
    "\n",
    "print(\"\\n\\033[1m Acuracy the \\033[1;31m Extra Trees\\033[1m: \\033[1;34m %1.2f%% \\033[0m\" % (metascore2.mean() * 100))\n",
    "print(\"\\033[1m Margin of Error for More and Less: \\033[1;34m %1.2f%% \\n\" % (metascore2.std() * 100))\n",
    "\n",
    "print(\"\\n\\033[1m Acuracy the \\033[1;31m Gradient Boosting\\033[1m: \\033[1;34m %1.2f%% \\033[0m\" % (metascore3.mean() * 100))\n",
    "print(\"\\033[1m Margin of Error for More and Less: \\033[1;34m %1.2f%% \\n\" % (metascore3.std() * 100))\n",
    "\n",
    "print(\"\\n\\033[1m Acuracy the \\033[1;31m Voting\\033[1m: \\033[1;34m %1.2f%% \\033[0m\" % (metascore4.mean() * 100))\n",
    "print(\"\\033[1m Margin of Error for More and Less: \\033[1;34m %1.2f%% \\n\" % (metascore4.std() * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
